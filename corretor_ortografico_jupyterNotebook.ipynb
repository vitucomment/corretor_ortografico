{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26d0042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\victo\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\victo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#   Foi usado '!pip install nltk' para fazer a instalação da biblioteca NLTK\n",
    "#  O import foi realizado no nosso código 'import nltk'\n",
    "#  E por fim, usamos a função 'download' para baixar 'punkt', um modelo pronto de tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a30ec0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"dados/artigos.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "#   Abrindo um arquivo usando python: função 'open()' que recebe dois parametros\n",
    "#  1 - caminho do arquivo e o nome com extensão\n",
    "#  2 - o tipo de atividade que será executada; r:ler, w:escreve, x:cria_escreve, a:abre_escreve_append\n",
    "#   Como queremos o texto, devemos usar o comando 'with' e ao final 'as f' significa 'como file'\n",
    "# ficando da seguinte forma: COM A FUNÇÃO OPEN NO ARQUIVO X NO MODO DE LEITURA COMO UM FILE\n",
    "#   E então podemos passar as ações que serão feitas nesse aquivo, que nesse caso, salvamos dentro de uma variável seu conteúdo,\n",
    "# usando a função '.read()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0e165ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(corpus_textual):\n",
    "    lista_palavras = []\n",
    "    lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token.lower())\n",
    "    return lista_palavras\n",
    "\n",
    "lista_normalizada = separa_palavras(artigos)\n",
    "# NLTK - Conjunto de ferramentas que implementa diversos metodos e algoritmos para análise textual.\n",
    "# Tokens são strings que contém textos e sinais, são feitos com palavras separadas e pode-se usar o metodo split para extrair\n",
    "# Necessário para descobrir a quantidade de palavras no CorpusTextual\n",
    "\n",
    "#   A função 'separa_palavras()' recebe o CorpusTextual, usa a biblioteca 'nltk' e a funçãoo '.word_tokenize()' para criar\n",
    "# uma lista de tokens.\n",
    "#   O 'for' percorre toda a lista de tokens e questiona se o token é um caracter alphanumerico, se for verdade, ele é adcionado\n",
    "# na lista de palavras\n",
    "#   A função também aplica um lowerCase na palavra, normalizando sua saida.\n",
    "#   No 'return' da função, é feito com o método 'set()', para retornar elementos distintos\n",
    "\n",
    "#   Para tratar uma corpusTextual, só precisamos inicializa-lo em uma variável e passar como parametro da função 'separa_palavra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f8553ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________ FIM DO TRATAMENTO DO CORPUSTEXTUAL ________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea0d312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "#     A função 'insere_letras' recebe como parametro as possiveis formas de fatiamento de uma string, como recebem em forma de \n",
    "# tupla com indice (0,1), dividimos em E(querdo) e D(ireito)\n",
    "#     As possiveis inserções estão dentro da variável 'letras', o 'for' pegará letra por letra e vai adcionar a string fatiada\n",
    "#     O retorno dessa função, é uma lista com as possiveis inserções nas possiveis formas de fatiamento\n",
    "\n",
    "\n",
    "def inverte_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "#     A função 'inverte_caracteres' recebe como parametro as possiveis formas de fatiamento de uma string, \n",
    "# como recebem em forma de tupla com indice (0,1), dividimos em E(querdo) e D(ireito)\n",
    "#     Dentro de um 'for', percorre-se todas as fatias, trocando a letra de indice[0] pela letra de indice[1], sempre que o tamanho\n",
    "# do lado D(ireito) seja maior que 1, para que possa ocorrer a troca e o erro 'out_of_range' não ocorrer\n",
    "#     Dessa forma, a função retorna todas as possiveis inversões\n",
    "\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "  \n",
    "#     A função 'deletando_caracteres' recebe como parametro as possiveis formas de fatiamento de uma string, \n",
    "# como recebem em forma de tupla com indice (0,1), dividimos em E(querdo) e D(ireito)\n",
    "#     Dentro de um 'for', percorre-se todas as fatias concatenando o lado E(querdo) completo e o D(ireito) fatiado a partir do \n",
    "# primeiro caracter, fazendo com que a cada loop, uma palavra é gerada excluindo possiveis caracteres escritos a mais.\n",
    "#     O retorno dessa função, é uma lista com as possiveis exclusões nas possiveis formas de fatiamento \n",
    "\n",
    "\n",
    "def troca_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "   \n",
    "#     A função 'troca_caractere' recebe como parametro as possiveis formas de fatiamento de uma string, \n",
    "# como recebem em forma de tupla com indice (0,1), dividimos em E(querdo) e D(ireito)\n",
    "#     Dentro de um 'for', percorre-se todas as fatias concatenando o lado E(querdo) completo e o D(ireito) fatiado a partir do \n",
    "# primeiro caracter e adicionando uma letra no lugar da primeira letra do lado direito, que foi deletada\n",
    "#     Dessa forma fazemos uma troca de todas as formas possiveis e salvamos numa lista.\n",
    "# O retorno dessa função, é uma lista com as possiveis trocas nas possiveis formas de fatiamento \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e8d9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "#   A função 'corretor', vai chamar a função 'gerador_palavras' dentro de uma variável 'palavras_geradas', \n",
    "# vai criar uma variável 'palavra_correta' que recebe uma built-in chamada 'max', que retorna a probabilidade \n",
    "# de cada uma das palavras geradas ser a palavra correta\n",
    "#   São passados dois parametros para a função 'max'\n",
    "#  1 - 'palavras_geradas': Variável criada que recebe o retorno da função 'gerador_palavras()'\n",
    "#  2 - 'key=probabildiade': Função que calcula a probabilidade da palavra correta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e225de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "def probabilidade(palavra_gerada):\n",
    "    total_palavras = len(lista_normalizada)\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "#   Para calcular a frequencia das palavras, usamos uma função da biblioteca nltk, 'nltk.FreqDist, que calcula\n",
    "# a distribuição de frequencia das palavras, recebe como parametro a lista de palavras do corpusTextual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9946c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para testar a funcionalidade do corretor, passe como parametro da função 'corretor()' a palavrada desejada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d491ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________ FIM DA CRIAÇÃO DAS FUNÇÔES DE CORRETOR ________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "312e7204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 76.34%\n"
     ]
    }
   ],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding = 'utf-8')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste('dados/palavras.txt')\n",
    "\n",
    "#   Uma função, que vai criar dados para testar na função avaliadora, é criada, nela passamos o aquivo de testes e tratamos\n",
    "# para que retorne uma lista com essas palavras\n",
    "\n",
    "def avaliador(testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = acertou/numero_palavras\n",
    "    print(f'Taxa de acerto: {round((taxa_acerto)*100,2)}%')\n",
    "    \n",
    "#   A função 'avaliador()' foi criada afim de testar a taxa de acerto fazendo com que o 'corretor()' corrija uma lista de \n",
    "# palavras, passando as corretas para a avaliação.\n",
    "#   O resultado evidencia que o programa ainda precisa ser aprimorado (~1.08%)\n",
    "#   Essa função auxilia no desenvolvimento do programa para contestar sua acuracidade \n",
    "\n",
    "avaliador(lista_teste)\n",
    "# Taxa de acerto com a lista teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e76ef334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________ FIM DA CRIAÇÃO DA ESTAÇÃO DE TESTES ________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d83cf1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for index in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:index],palavra[index:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_caracteres(fatias)\n",
    "    palavras_geradas += inverte_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "    \n",
    "#     A função 'gerador_palavras' usa algoritmos que criam todas as possiveis formas de fatiamento de uma string, passeando\n",
    "# pelo index de acordo com o 'len'\n",
    "#     Assim, qualquer palavra que for escrita e for passada como parâmetro da função 'gerador_palavras()', passará pelas\n",
    "# funções de algoritmo, gerando todas as possiveis correções, limitadas ao algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e65bf49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8722c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
