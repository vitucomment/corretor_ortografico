{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "26d0042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\victo\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\victo\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\victo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#   Foi usado '!pip install nltk' para fazer a instalação da biblioteca NLTK\n",
    "#  O import foi realizado no nosso código 'import nltk'\n",
    "#  E por fim, usamos a função 'download' para baixar 'punkt', um modelo pronto de tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a30ec0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"dados/artigos.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "#   Abrindo um arquivo usando python: função 'open()' que recebe dois parametros\n",
    "#  1 - caminho do arquivo e o nome com extensão\n",
    "#  2 - o tipo de atividade que será executada; r:ler, w:escreve, x:cria_escreve, a:abre_escreve_append\n",
    "#   Como queremos o texto, devemos usar o comando 'with' e ao final 'as f' significa 'como file'\n",
    "# ficando da seguinte forma: COM A FUNÇÃO OPEN NO ARQUIVO X NO MODO DE LEITURA COMO UM FILE\n",
    "#   E então podemos passar as ações que serão feitas nesse aquivo, que nesse caso, salvamos dentro de uma variável seu conteúdo,\n",
    "# usando a função '.read()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d0e165ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(corpus_textual):\n",
    "    lista_palavras = []\n",
    "    lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token.lower())\n",
    "    return lista_palavras\n",
    "\n",
    "# NLTK - Conjunto de ferramentas que implementa diversos metodos e algoritmos para análise textual.\n",
    "# Tokens são strings que contém textos e sinais, são feitos com palavras separadas e pode-se usar o metodo split para extrair\n",
    "# Necessário para descobrir a quantidade de palavras no CorpusTextual\n",
    "\n",
    "#   A função 'separa_palavras()' recebe o CorpusTextual, usa a biblioteca 'nltk' e a funçãoo '.word_tokenize()' para criar\n",
    "# uma lista de tokens.\n",
    "#   O 'for' percorre toda a lista de tokens e questiona se o token é um caracter alphanumerico, se for verdade, ele é adcionado\n",
    "# na lista de palavras\n",
    "#   A função também aplica um lowerCase na palavra, normalizando sua saida.\n",
    "#   No 'return' da função, é feito com o método 'set()', para retornar elementos distintos\n",
    "\n",
    "#   Para tratar uma corpusTextual, só precisamos inicializa-lo em uma variável e passar como parametro da função 'separa_palavra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1f8553ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________ FIM DO TRATAMENTO DO CORPUSTEXTUAL ________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ea0d312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "#   A função 'insere_letras' recebe como parametro as possiveis formas de fatiamento de uma string, como recebem em forma de \n",
    "# tupla com indice (0,1), dividimos em E(querdo) e D(ireito)\n",
    "#   As possiveis inserções estão dentro da variável 'letras', o 'for' pegará letra por letra e vai adcionar a string fatiada\n",
    "#   O retorno dessa função, é uma lista com as possiveis inserções nas possiveis formas de fatiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bfde151d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for index in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:index],palavra[index:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "#   A função 'gerador_palavras' usa um algoritmo que cria todas as possiveis formas de fatiamento de uma string, passeando\n",
    "# pelo index de acordo com o 'len'\n",
    "#   O retorno é a variavel 'palavras_geradas' que recebe o valore de retorno da função 'insere_letras()' que recebeu como\n",
    "# parâmetro as fatias geradas dentro do 'for'\n",
    "#   Assim, qualquer palavra que for escrita e for passada como parâmetro da função 'gerador_palavras()' vai ter como retorno\n",
    "# todas as possiveis formas de inserção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2e8d9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "#   A função 'corretor', vai chamar a função 'gerador_palavras' dentro de uma variável 'palavras_geradas', \n",
    "# vai criar uma variável 'palavra_correta' que recebe uma built-in chamada 'max', que retorna a probabilidade \n",
    "# de cada uma das palavras geradas ser a palavra correta\n",
    "#   São passados dois parametros para a função 'max'\n",
    "#  1 - 'palavras_geradas': Variável criada que recebe o retorno da função 'gerador_palavras()'\n",
    "#  2 - 'key=probabildiade': Função que calcula a probabilidade da palavra correta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e225de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "def probabilidade(palavra_gerada):\n",
    "    total_palavras = len(lista_normalizada)\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "#   Para calcular a frequencia das palavras, usamos uma função da biblioteca nltk, 'nltk.FreqDist, que calcula\n",
    "# a distribuição de frequencia das palavras, recebe como parametro a lista de palavras do corpusTextual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a08e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para testar a funcionalidade do corretor, passe como parametro da função 'corretor()' a palavrada desejada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "013e5aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desejada'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor('deseada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04953397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
